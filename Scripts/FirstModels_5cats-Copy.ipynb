{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open('../Data/labeledhate_5cats.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoonTown</td>\n",
       "      <td>cqug92k</td>\n",
       "      <td>t1_cqug92k</td>\n",
       "      <td>&amp;gt;maybe jews\\n\\nnot maybe</td>\n",
       "      <td>RaceHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CoonTown</td>\n",
       "      <td>cqug9f5</td>\n",
       "      <td>t1_cqug9f5</td>\n",
       "      <td>juh-juh-juh-juh-juh-juh-just cant even</td>\n",
       "      <td>RaceHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CoonTown</td>\n",
       "      <td>cqug9wy</td>\n",
       "      <td>t1_cqug9wy</td>\n",
       "      <td>I like the idea...have an upvote!</td>\n",
       "      <td>RaceHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoonTown</td>\n",
       "      <td>cquga8b</td>\n",
       "      <td>t1_cquga8b</td>\n",
       "      <td>Never underestimate the stupidity of niggers. ...</td>\n",
       "      <td>RaceHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoonTown</td>\n",
       "      <td>cquga92</td>\n",
       "      <td>t1_cquga92</td>\n",
       "      <td>Someone has deeper internal issues they have w...</td>\n",
       "      <td>RaceHate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit       id        name  \\\n",
       "0  CoonTown  cqug92k  t1_cqug92k   \n",
       "1  CoonTown  cqug9f5  t1_cqug9f5   \n",
       "2  CoonTown  cqug9wy  t1_cqug9wy   \n",
       "3  CoonTown  cquga8b  t1_cquga8b   \n",
       "4  CoonTown  cquga92  t1_cquga92   \n",
       "\n",
       "                                                body     label  \n",
       "0                        &gt;maybe jews\\n\\nnot maybe  RaceHate  \n",
       "1             juh-juh-juh-juh-juh-juh-just cant even  RaceHate  \n",
       "2                  I like the idea...have an upvote!  RaceHate  \n",
       "3  Never underestimate the stupidity of niggers. ...  RaceHate  \n",
       "4  Someone has deeper internal issues they have w...  RaceHate  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848185            He's like Poppins from It's always Sunny.\n",
       "917229    As a Londoner thats currently in Cambridge, I ...\n",
       "406707    Ah yes I always forget about aviation. Well th...\n",
       "667836                                            [deleted]\n",
       "979603    Is the Nepal earthquake still a thing? I thoug...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473426,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with sk-learn models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(stop_words='english', decode_error = 'ignore')\n",
    "tfidf_fit = tfidf_v.fit_transform(X_train)\n",
    "#test vector\n",
    "tfidf_fit_test = tfidf_v.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training vector\n",
    "countv = CountVectorizer(decode_error = 'ignore', stop_words = 'english')\n",
    "countv_fit = countv.fit_transform(X_train)\n",
    "#test vector\n",
    "countv_fit_test = countv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hashvect = HashingVectorizer(stop_words='english', decode_error = 'ignore', non_negative=True)\n",
    "# train vector\n",
    "hashvectfit = hashvect.fit_transform(X_train)\n",
    "# test vector\n",
    "hashvectfit_test = hashvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848185        NotHate\n",
       "917229        NotHate\n",
       "406707       SizeHate\n",
       "667836        NotHate\n",
       "979603        NotHate\n",
       "528009       SizeHate\n",
       "1315021       NotHate\n",
       "870102        NotHate\n",
       "1169077       NotHate\n",
       "702346        NotHate\n",
       "1389627       NotHate\n",
       "873782        NotHate\n",
       "587043        NotHate\n",
       "271605       SizeHate\n",
       "1373693       NotHate\n",
       "612479        NotHate\n",
       "1453210       NotHate\n",
       "359292       SizeHate\n",
       "1524312       NotHate\n",
       "944535        NotHate\n",
       "826690        NotHate\n",
       "399093       SizeHate\n",
       "1560370       NotHate\n",
       "1478906       NotHate\n",
       "1295130       NotHate\n",
       "666487        NotHate\n",
       "1395165       NotHate\n",
       "519938       SizeHate\n",
       "821413        NotHate\n",
       "53162        RaceHate\n",
       "              ...    \n",
       "1470485       NotHate\n",
       "1396025       NotHate\n",
       "184779     GenderHate\n",
       "1262752       NotHate\n",
       "1284372       NotHate\n",
       "103355     GenderHate\n",
       "791743        NotHate\n",
       "1247617       NotHate\n",
       "327069       SizeHate\n",
       "1370455       NotHate\n",
       "787201        NotHate\n",
       "1113396       NotHate\n",
       "329365       SizeHate\n",
       "41090        RaceHate\n",
       "278167       SizeHate\n",
       "1239911       NotHate\n",
       "175203     GenderHate\n",
       "912756        NotHate\n",
       "1136074       NotHate\n",
       "1570006       NotHate\n",
       "999890        NotHate\n",
       "137337     GenderHate\n",
       "1103462       NotHate\n",
       "732180        NotHate\n",
       "110268     GenderHate\n",
       "259178       SizeHate\n",
       "1414414       NotHate\n",
       "131932     GenderHate\n",
       "671155        NotHate\n",
       "121958     GenderHate\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict \n",
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using hashing vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNBvect = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_hash = MNBvect.fit(hashvectfit, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashpreds = model_hash.predict(hashvectfit_test)\n",
    "hashpreds_prob = model_hash.predict_proba(hashvectfit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67711954983460987"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hash.score(hashvectfit_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GenderHate', 'NotHate', 'RaceHate', 'ReligionHate', 'SexOrHate',\n",
       "       'SizeHate'], \n",
       "      dtype='|S12')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the name of the classes used\n",
    "model_hash.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NotHate', 'NotHate', 'NotHate', 'NotHate', 'NotHate', 'NotHate',\n",
       "       'SizeHate', 'NotHate', 'NotHate', 'NotHate'], \n",
       "      dtype='|S12')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashpreds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.77617153e-03,   8.73342290e-01,   1.13513539e-04,\n",
       "          2.97341162e-07,   5.05560194e-08,   1.23767677e-01],\n",
       "       [  7.48087278e-03,   9.82061704e-01,   2.71540897e-04,\n",
       "          4.51370407e-07,   8.11350104e-09,   1.01854231e-02],\n",
       "       [  5.45005943e-02,   8.75485219e-01,   5.11751599e-03,\n",
       "          1.12807333e-05,   1.61231716e-06,   6.48837779e-02],\n",
       "       [  1.13457222e-01,   8.36631682e-01,   1.57993658e-03,\n",
       "          8.10953381e-06,   8.25386048e-07,   4.83222241e-02],\n",
       "       [  1.91755279e-04,   9.99684783e-01,   3.19022274e-07,\n",
       "          1.95804228e-13,   7.15720426e-16,   1.23142993e-04],\n",
       "       [  3.47313144e-08,   9.99999964e-01,   4.51064088e-12,\n",
       "          9.77546176e-19,   2.63860503e-22,   8.87175255e-10],\n",
       "       [  1.17650019e-02,   4.87457864e-01,   1.15998220e-03,\n",
       "          6.45221784e-06,   1.49488584e-06,   4.99609205e-01],\n",
       "       [  9.30854478e-02,   8.86010091e-01,   4.60622851e-03,\n",
       "          1.86592029e-04,   1.01022427e-04,   1.60106184e-02],\n",
       "       [  1.84582553e-01,   6.25229692e-01,   3.84459772e-03,\n",
       "          3.61193544e-05,   9.09504484e-06,   1.86297943e-01],\n",
       "       [  2.14078759e-02,   9.41535538e-01,   7.35111314e-04,\n",
       "          6.40601142e-07,   1.82053780e-07,   3.63206523e-02]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashpreds_prob[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_cv = MNBvect.fit(countv_fit, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvpreds = model_cv.predict(countv_fit_test)\n",
    "cvpreds_prob = model_cv.predict_proba(countv_fit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75784811142607289"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv.score(countv_fit_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tf-idf (though MultinomialNB may not work as well with fractional counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_tfidf = MNBvect.fit(tfidf_fit, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfpred = model_tfidf.predict(tfidf_fit_test)\n",
    "tfidfpred_prob = model_tfidf.predict_proba(tfidf_fit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73381901289747498"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tfidf.score(tfidf_fit_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try count vectorizer with random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcv_rfc = rfc.fit_transform(countv_fit, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcv_rfc.score(countv_fit_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelcv_rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### To create ROC curve:\n",
    "# Need to use one columns of prediction probabilities with one row of 1s & 0s --> build up ROC curve for each class.\n",
    "# Ming thinks it's fine to rely on the accuracy score in this case, since it's multiclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)\n",
    "roc_auc_score(y_true, y_scores)  #roc_auc_score(y_test, hashpreds, average = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
