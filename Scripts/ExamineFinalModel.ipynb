{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from string import punctuation\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import snowball\n",
    "import xgboost as xgb\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = snowball.SnowballStemmer(\"english\")\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    '''Stem the tokens.'''\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    '''Tokenize & stem. Stems automatically for now.\n",
    "    Leaving \"stemmer\" out of function call, so it works with TfidfVectorizer'''\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write function to grab the feature importances & show top ~20\n",
    "\n",
    "def top_features_words(d,vect, n=20):\n",
    "    '''\n",
    "    Function to show the top n important features, their scores,and corresponding words.\n",
    "    The get_fscore method in xgboost returns a dictionary of features & a number.\n",
    "    Get the top n features with the highest scores\n",
    "    \n",
    "    d is a dictionary (from bst.get_fscore() in xgboost)\n",
    "    vect is the instantiated vectorizer (e.g. vect = TfidfVectorizer(stuff); not the fitted variable name)\n",
    "    '''\n",
    "    \n",
    "    # Back out important features\n",
    "\n",
    "    dicta = vect.vocabulary_\n",
    "    dictb = dict ( (v,k) for k, v in dicta.items() )\n",
    "    # dictb[featurenum] returns the word.\n",
    "\n",
    "    featureslist = []\n",
    "    for k, v in sorted(d.iteritems(), reverse=True, key=lambda (k,v): (v,k)):\n",
    "        featureslist.append((k,v))\n",
    "    \n",
    "    topfeatures = []\n",
    "    for i in xrange(n):\n",
    "        fname = featureslist[i][0]\n",
    "        fnum=int(filter(lambda x: x.isdigit(),fname))\n",
    "        topfeatures.append((featureslist[i][0],featureslist[i][1],dictb[fnum]))\n",
    "    \n",
    "    return topfeatures\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     To load saved model:\n",
    "#     bst = xgb.Booster({'nthread': 4}) #init model\n",
    "#     bst.load_model(\"model.bin\")  <-- I think this should be \"hatespeech.model\"\n",
    "\n",
    "#     Or, if pickled:\n",
    "#     bst = pickle.load(open('bst.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to predict:\n",
    "#  Need to fit comment to tf-idf vector\n",
    "#  convert tf-idf to xgb dmatrix\n",
    "#  Call that in prediction\n",
    "\n",
    "# yprob = bst.predict( xg_test ).reshape( y_test.shape[0], 5 )\n",
    "# xg_test = xgb.DMatrix(tfidfv_fit_X_test, label=y_test)\n",
    "# tfidfv_fit_X_test = tfidfv.transform(X_test)\n",
    "# X_test : \"an iterable which yields either str, unicode or file objects\"\n",
    "# e.g. X_test = vectorizer.transform((open(f).read() for f in news_test.filenames))\n",
    "\n",
    "\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "#yprob = bst.predict( xg_test ).reshape( y_test.shape[0], 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.Booster()\n",
    "bst.load_model('../FinalModel/BuildModel/hatespeech.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load vectors\n",
    "tfidf_X = pickle.load(open('../FinalModel/BuildModel/tfidf_X.p', 'rb'))\n",
    "vect = pickle.load(open('../FinalModel/BuildModel/vect.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes=['Not Hate', 'Size Hate', 'Gender Hate', 'Race Hate', 'Religion Hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter comment: I think fat people are not jerks.\n"
     ]
    }
   ],
   "source": [
    "comment = [raw_input('Enter comment: ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class is: Size Hate with probability 83.8%\n"
     ]
    }
   ],
   "source": [
    "comment_tfidf = vect.transform(comment) # double check... is this transforming to test vector?\n",
    "comment_xgb = xgb.DMatrix(comment_tfidf)\n",
    "yprob = bst.predict(comment_xgb).reshape(1,5) # hard coding -- only one comment at a time in this case.\n",
    "\n",
    "ylabel = classes[np.argmax(yprob, axis=1)]\n",
    "\n",
    "print('The class is: {0} with probability {1}%'.format(ylabel, round(100*np.max(yprob),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f255261', 852, u'like'),\n",
       " ('f310038', 768, u'peopl'),\n",
       " ('f242158', 761, u'just'),\n",
       " ('f128396', 637, u'fat'),\n",
       " ('f109214', 530, u'dont'),\n",
       " ('f227631', 431, u'im'),\n",
       " ('f55520', 401, u'becaus'),\n",
       " ('f139322', 366, u'fuck'),\n",
       " ('f395295', 360, u'think'),\n",
       " ('f263062', 296, u'make'),\n",
       " ('f352019', 279, u'say'),\n",
       " ('f433573', 277, u'white'),\n",
       " ('f141754', 269, u'game'),\n",
       " ('f258673', 253, u'look'),\n",
       " ('f246769', 248, u'know'),\n",
       " ('f60685', 231, u'black'),\n",
       " ('f148767', 219, u'good'),\n",
       " ('f113906', 216, u'eat'),\n",
       " ('f394947', 215, u'thing'),\n",
       " ('f300231', 215, u'onli'),\n",
       " ('f400097', 212, u'time'),\n",
       " ('f436656', 211, u'women'),\n",
       " ('f428393', 193, u'want'),\n",
       " ('f431153', 189, u'weight'),\n",
       " ('f318901', 178, u'post'),\n",
       " ('f361157', 169, u'shit'),\n",
       " ('f239627', 168, u'jew'),\n",
       " ('f342871', 164, u'right'),\n",
       " ('f285454', 147, u'need'),\n",
       " ('f419812', 144, u'use'),\n",
       " ('f433376', 143, u'whi'),\n",
       " ('f287913', 143, u'nigger'),\n",
       " ('f39551', 142, u'ani'),\n",
       " ('f334728', 141, u'realli'),\n",
       " ('f162484', 136, u'guy'),\n",
       " ('f429915', 135, u'way'),\n",
       " ('f295957', 134, u'obes'),\n",
       " ('f29462', 128, u'actual'),\n",
       " ('f269941', 128, u'men'),\n",
       " ('f135376', 128, u'food'),\n",
       " ('f152281', 125, u'gt'),\n",
       " ('f437463', 122, u'work'),\n",
       " ('f91595', 121, u'countri'),\n",
       " ('f441595', 114, u'year'),\n",
       " ('f405444', 114, u'tri'),\n",
       " ('f149475', 113, u'got'),\n",
       " ('f263764', 105, u'man'),\n",
       " ('f311273', 104, u'person'),\n",
       " ('f370026', 98, u'someon'),\n",
       " ('f98379', 96, u'day')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features_words(bst.get_fscore(),vect, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.50739864e-01,   8.38145196e-01,   8.80795345e-03,\n",
       "          2.14899029e-03,   1.58049195e-04]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455756"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SizeHate'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "th {\n",
       "background-color:#55FF33;\n",
       "\\}\n",
       "td {\n",
       "background-color:#00FFFF;\n",
       "\\}\n",
       "</style>\n",
       "<table><tr><th>bar</th><th>bar</th></tr><tr><td>foo</td><td>foo</td></tr></table>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "        \"\"\"\n",
    "    <style>\n",
    "th {\n",
    "background-color:#55FF33;\n",
    "\\}\n",
    "td {\n",
    "background-color:#00FFFF;\n",
    "\\}\n",
    "</style>\n",
    "<table><tr><th>bar</th><th>bar</th></tr><tr><td>foo</td><td>foo</td></tr></table>\n",
    "    \"\"\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
